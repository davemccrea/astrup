defmodule Astrup.Datasets.PTBXL.Parser do
  import NimbleParsec

  @moduledoc """
  Parser for PTB-XL database CSV files using NimbleParsec.

  The PTB-XL database contains ECG data with 28 columns including:
  - Basic patient info (id, age, sex, height, weight)
  - Recording metadata (nurse, site, device, date)
  - Medical reports and SCP codes (parsed from Python dict format)
  - File paths for different resolution recordings

  ## Key Features
  - Robust CSV parsing with NimbleParsec (handles quoted fields with commas)
  - SCP codes conversion from Python dict format to Elixir maps
  - Comprehensive type conversion for all fields
  - Proper handling of missing/empty values
  """

  @header_fields [
    :ecg_id,
    :patient_id,
    :age,
    :sex,
    :height,
    :weight,
    :nurse,
    :site,
    :device,
    :recording_date,
    :report,
    :scp_codes,
    :heart_axis,
    :infarction_stadium1,
    :infarction_stadium2,
    :validated_by,
    :second_opinion,
    :initial_autogenerated_report,
    :validated_by_human,
    :baseline_drift,
    :static_noise,
    :burst_noise,
    :electrodes_problems,
    :extra_beats,
    :pacemaker,
    :strat_fold,
    :filename_lr,
    :filename_hr
  ]

  @doc """
  Parse a PTB-XL CSV file and return structured data.

  Reads the CSV file and parses it using NimbleParsec for robust handling
  of quoted fields containing commas (especially important for scp_codes).

  ## Returns
  - `{:ok, %{header: list, rows: list}}` on success
  - `{:error, reason}` on failure

  ## Examples

      iex> Astrup.Datasets.PTBXL.Parser.parse_file("ptbxl_database.csv")
      {:ok, %{
        header: [:ecg_id, :patient_id, :age, :sex, ...],
        rows: [%{ecg_id: 1, scp_codes: %{"NORM" => 100.0}, ...}, ...]
      }}
  """
  def parse_file(filename) do
    case File.read(filename) do
      {:ok, content} ->
        parse_string(content)

      {:error, reason} ->
        {:error, "File read error: #{reason}"}
    end
  end

  @doc """
  Parse PTB-XL CSV content from a string.

  Processes the raw CSV content, splitting into lines and parsing each row
  using the NimbleParsec-based CSV parser. Converts all fields to appropriate
  Elixir types.

  ## Parameters
  - `content` - Raw CSV content as a string

  ## Returns
  - `{:ok, %{header: list, rows: list}}` on success
  - `{:error, reason}` on parse failure
  """
  def parse_string(content) do
    try do
      lines = String.split(content, ~r/\r?\n/, trim: true)
      [_header | rows] = lines

      parsed_rows =
        rows
        |> Enum.map(&parse_csv_row/1)
        |> Enum.map(&row_to_map/1)

      {:ok, %{header: @header_fields, rows: parsed_rows}}
    rescue
      e -> {:error, "Parse error: #{Exception.message(e)}"}
    end
  end

  # CSV parsing using NimbleParsec
  # Handles quoted fields with commas, escaped quotes, and proper CSV structure
  # This is essential for parsing scp_codes field which contains Python dict format
  # Handle escaped quotes within quoted fields (\"\" becomes \")
  escaped_quote = string("\"\"") |> replace("\"")

  # Content inside quoted fields - can contain escaped quotes or any non-quote character
  quoted_content =
    choice([
      escaped_quote,
      utf8_char([{:not, ?"}])
    ])
    |> repeat()
    |> reduce({IO, :iodata_to_binary, []})

  # Quoted field: \"content\" (handles commas and other special chars inside)
  quoted_field =
    ignore(string("\""))
    |> concat(quoted_content)
    |> ignore(string("\""))

  # Unquoted field: any characters except comma, CR, LF
  unquoted_field =
    utf8_char([{:not, ?,}, {:not, ?\r}, {:not, ?\n}])
    |> repeat()
    |> reduce({IO, :iodata_to_binary, []})

  # A field can be either quoted or unquoted
  field = choice([quoted_field, unquoted_field])

  # CSV row parser: field followed by comma-separated fields, optional line ending
  defparsec(
    :csv_row,
    field
    |> repeat(ignore(string(",")) |> concat(field))
    |> optional(ignore(choice([string("\r\n"), string("\n"), string("\r")])))
  )

  # Parse a single CSV row using the NimbleParsec parser
  defp parse_csv_row(line) do
    case csv_row(line) do
      {:ok, fields, _rest, _context, _line, _column} ->
        fields
        |> Enum.map(&String.trim/1)
        |> Enum.map(&fix_encoding/1)
    end
  end

  # Fix encoding issues in CSV fields (convert Latin-1 to UTF-8)
  # The PTB-XL dataset contains German medical reports with special characters
  # (ä, ö, ü, ß) that are encoded in Latin-1 but need to be converted to UTF-8
  # for proper display in Elixir strings
  defp fix_encoding(field) do
    case String.valid?(field) do
      true ->
        field

      false ->
        # Try to convert from Latin-1 to UTF-8
        case :unicode.characters_to_binary(field, :latin1, :utf8) do
          # If conversion fails, keep original
          {:error, _, _} -> field
          converted -> converted
        end
    end
  end

  defp row_to_map(row_data) do
    Enum.zip(@header_fields, row_data)
    |> Enum.into(%{})
    |> convert_types()
  end

  defp convert_types(row) do
    row
    |> convert_integers([:ecg_id, :strat_fold])
    |> convert_floats([:patient_id, :age, :weight, :height, :nurse, :site])
    |> convert_booleans([:validated_by_human, :second_opinion, :initial_autogenerated_report])
    |> convert_datetime(:recording_date)
    |> convert_scp_codes(:scp_codes)
    |> convert_sex(:sex)
    |> convert_heart_axis(:heart_axis)
    |> convert_infarction_stadium(:infarction_stadium1)
    |> convert_infarction_stadium(:infarction_stadium2)
  end

  defp convert_integers(row, fields) do
    Enum.reduce(fields, row, fn field, acc ->
      case Map.get(acc, field) do
        "" ->
          Map.put(acc, field, nil)

        value ->
          try do
            Map.put(acc, field, String.to_integer(value))
          rescue
            ArgumentError -> Map.put(acc, field, nil)
          end
      end
    end)
  end

  defp convert_floats(row, fields) do
    Enum.reduce(fields, row, fn field, acc ->
      case Map.get(acc, field) do
        "" ->
          Map.put(acc, field, nil)

        value ->
          case Float.parse(value) do
            {float, _} -> Map.put(acc, field, float)
            :error -> Map.put(acc, field, nil)
          end
      end
    end)
  end

  defp convert_booleans(row, fields) do
    Enum.reduce(fields, row, fn field, acc ->
      case Map.get(acc, field) do
        "True" -> Map.put(acc, field, true)
        "False" -> Map.put(acc, field, false)
        _ -> Map.put(acc, field, nil)
      end
    end)
  end

  defp convert_datetime(row, field) do
    case Map.get(row, field) do
      "" ->
        Map.put(row, field, nil)

      value ->
        case NaiveDateTime.from_iso8601(String.replace(value, " ", "T")) do
          {:ok, datetime} -> Map.put(row, field, datetime)
          {:error, _} -> Map.put(row, field, nil)
        end
    end
  end

  # Convert SCP codes from Python dict format to Elixir map
  # Input: "{'NORM': 100.0, 'LVOLT': 0.0}" -> Output: %{"NORM" => 100.0, "LVOLT" => 0.0}
  defp convert_scp_codes(row, field) do
    case Map.get(row, field) do
      "" ->
        Map.put(row, field, %{})

      value ->
        case parse_python_dict(value) do
          {:ok, map} -> Map.put(row, field, map)
          {:error, _} -> Map.put(row, field, %{})
        end
    end
  end

  # Convert sex field: "0" -> 0 (female), "1" -> 1 (male)
  defp convert_sex(row, field) do
    case Map.get(row, field) do
      "0" -> Map.put(row, field, 0)
      "1" -> Map.put(row, field, 1)
      _ -> Map.put(row, field, nil)
    end
  end

  defp convert_heart_axis(row, field) do
    case Map.get(row, field) do
      "LAD" -> Map.put(row, field, :LAD)
      "RAD" -> Map.put(row, field, :RAD)
      "LAFB" -> Map.put(row, field, :LAFB)
      "LPFB" -> Map.put(row, field, :LPFB)
      "" -> Map.put(row, field, nil)
      value -> Map.put(row, field, String.to_atom(value))
    end
  end

  defp convert_infarction_stadium(row, field) do
    case Map.get(row, field) do
      "acute" -> Map.put(row, field, :acute)
      "old" -> Map.put(row, field, :old)
      "unknown" -> Map.put(row, field, :unknown)
      "" -> Map.put(row, field, nil)
      value -> Map.put(row, field, String.to_atom(value))
    end
  end

  # Parse Python dictionary format from SCP codes field
  # Converts format like "{'NORM': 100.0, 'LVOLT': 0.0}" to Elixir map
  defp parse_python_dict(str) do
    try do
      str
      # Replace single quotes with double quotes
      |> String.replace("'", "\"")
      # Ensure proper JSON format
      |> String.replace(~r/(\w+):\s*([0-9.]+)/, "\"\\1\": \\2")
      # Parse as JSON
      |> Jason.decode()
    rescue
      _ -> {:error, :invalid_format}
    end
  end
end
